{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6tPO_MhH_a_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#for xml\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "#PyTorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torchvision\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Image processing\n",
        "from PIL import Image, ImageDraw, ExifTags, ImageColor, ImageFont\n",
        "\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEO1HckDH6Mn",
        "outputId": "88fab248-1968-4a61-f2aa-d349661d8bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#moungting to Google Drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-FBOrpXH-u_"
      },
      "outputs": [],
      "source": [
        "#introducing annotations and images\n",
        "annotation_path = 'gdrive/My Drive/Colab Notebooks/Image/Dataset/annotations'\n",
        "images_path = 'gdrive/My Drive/Colab Notebooks/Image/Dataset/images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa2mhp1JMyfK"
      },
      "outputs": [],
      "source": [
        "def encoded_labels(labels_list):\n",
        "    encoded=[]\n",
        "    for label in labels_list:\n",
        "        if label == \"with_mask\":\n",
        "            code = 1\n",
        "        elif label == \"mask_weared_incorrect\":\n",
        "            code = 2\n",
        "        elif label == \"without_mask\":\n",
        "            code = 3\n",
        "        else:\n",
        "            code = 0 #background\n",
        "        encoded.append(code)\n",
        "    return encoded  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDYvzSk6P60b"
      },
      "outputs": [],
      "source": [
        "def decode_labels(labels_list):\n",
        "    labels=[]\n",
        "    for code in labels_list:\n",
        "        if code == 1:\n",
        "            label = \"with_mask\"\n",
        "        elif code == 2:\n",
        "            label = \"mask_weared_incorrect\"\n",
        "        elif code == 3:\n",
        "            label = \"without_mask\"\n",
        "        else:\n",
        "            label = 'background'\n",
        "        labels.append(label)\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4WmfsUm0F-W"
      },
      "outputs": [],
      "source": [
        "class Data(Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self, annotation_path, images_path, transform=None, mode=None):\n",
        "\n",
        "        # Image directories\n",
        "        self.annotation_path = annotation_path\n",
        "        self.images_path = images_path\n",
        "        # The transform is goint to be used on image\n",
        "        self.transform = transform\n",
        "        # Create dataframe to hold info\n",
        "        self.data = pd.DataFrame(columns=['Filename', 'BoundingBoxes', 'Labels', 'Area', 'Number_of_Objects'])\n",
        "        \n",
        "        # Append rows with image filename and respective bounding boxes to the df\n",
        "        for file in enumerate(os.listdir(images_path)):\n",
        "            # Find image annotation file\n",
        "            ann_file_path = os.path.join(annotation_path, file[1][:-4]) + '.xml'\n",
        "            # Read XML file and return bounding boxes and class attributes\n",
        "            objects = self.read_XML(ann_file_path)\n",
        "            # getting the list of labels in an image\n",
        "            list_labels = encoded_labels(objects[0]['labels'])\n",
        "            # Create list of bounding boxes in an image\n",
        "            list_bb = []\n",
        "            list_area = []\n",
        "            n_obj = len(objects[0]['objects'])\n",
        "            for i in objects[0]['objects']:\n",
        "                new_list = [i['xmin'], i['ymin'], i['xmax'], i['ymax']]\n",
        "                list_bb.append(new_list)\n",
        "                list_area.append((i['xmax'] - i['xmin']) * (i['ymax'] - i['ymin']))\n",
        "\n",
        "            # Create dataframe object with row containing [(Image file name),(Bounding Box List)]\n",
        "            df = pd.DataFrame([[file, list_bb, list_labels, list_area, n_obj]],\n",
        "                              columns=['Filename', 'BoundingBoxes', 'Labels', 'Area', 'Number_of_Objects'])\n",
        "            self.data = self.data.append(df)\n",
        "\n",
        "        # Number of images in dataset\n",
        "        self.len = self.data.shape[0]\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.data = self.data[:680]\n",
        "        elif mode == 'validation':\n",
        "            self.data = self.data[680:700]\n",
        "        elif mode == 'test':\n",
        "            self.data = self.data[700:853]\n",
        "\n",
        "\n",
        "\n",
        "    # Get the length\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "   # Getter\n",
        "    def __getitem__(self, idx):\n",
        "        # Image file path\n",
        "        img_name = os.path.join(self.images_path, self.data.iloc[idx, 0])\n",
        "        # Open image file and tranform to tensor\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        # Get bounding box coordinates\n",
        "        bbox = torch.tensor(self.data.iloc[idx, 1])\n",
        "        # Get labels\n",
        "        labels = torch.tensor(self.data.iloc[idx, 2])\n",
        "        # Get bounding box areas\n",
        "        area = torch.tensor(self.data.iloc[idx, 3])\n",
        "\n",
        "        # If any, aplly tranformations to image and bounding box mask\n",
        "        if self.transform:\n",
        "            # Convert PIL image to numpy array\n",
        "            image  = np.array(image )\n",
        "            # Apply transformations\n",
        "            transformed = self.transform(image=img, bboxes=bbox)\n",
        "            # Convert numpy array to PIL Image\n",
        "            image  = Image.fromarray(transformed['image'])\n",
        "            # Get transformed bb\n",
        "            bbox = torch.tensor(transformed['bboxes'])\n",
        "\n",
        "        # suppose all instances are not crowd\n",
        "        num_objs = self.data.iloc[idx, 4]\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "        # Transform img to tensor\n",
        "        image = torchvision.transforms.ToTensor()(image)\n",
        "        # Build Targer dict\n",
        "        target= {\"boxes\": bbox, \"labels\": labels, \"image_id\": torch.tensor([idx]), \"area\": area, \"iscrowd\": iscrowd}\n",
        "\n",
        "        return image, target  \n",
        "    # XML reader -> returns dictionary with image bounding boxes sizes\n",
        "    def read_XML(self, annotation_path):\n",
        "        bboxes = [{\n",
        "            'file': annotation_path,\n",
        "            'labels': [],\n",
        "            'objects': []\n",
        "        }]\n",
        "\n",
        "        # Reading XML file objects and print Bounding Boxes\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "        objects = root.findall('object')\n",
        "       \n",
        "       #becuase we have multiobjects in the image\n",
        "        for obj in objects:\n",
        "            # label\n",
        "            label = obj.find('name').text  #without_mask/wtih_mask/mask_weared_incorrect\t\n",
        "            bboxes[0]['labels'].append(label)\n",
        "\n",
        "            # bbox dimensions\n",
        "            bndbox = obj.find('bndbox')\n",
        "            xmin = int(bndbox.find('xmin').text)\n",
        "            ymin = int(bndbox.find('ymin').text)\n",
        "            xmax = int(bndbox.find('xmax').text)\n",
        "            ymax = int(bndbox.find('ymax').text)\n",
        "            bboxes[0]['objects'].append({'xmin': xmin, 'ymin': ymin, 'xmax': xmax, 'ymax': ymax})\n",
        "\n",
        "        return bboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNuTuvZSIRm4"
      },
      "outputs": [],
      "source": [
        "dataset_train = Data(annotation_path,images_path, mode = 'train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SsbD3g8uS0yH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZcCluaaUU6V"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "INM_705_CW_Code_TS_v1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdFd/EO1zjC1BGfE+ArIiW"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}